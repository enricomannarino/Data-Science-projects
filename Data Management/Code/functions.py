# -*- coding: utf-8 -*-
"""Copy_Functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L5fXHDg2Nx6Fr03AtfKrELyRi5PijFw_
"""

import pandas as pd
import json
import re
from unidecode import unidecode
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
nltk.download('stopwords', quiet=True)
nltk.download('punkt')
from collections import defaultdict
from fuzzywuzzy import fuzz

# cleaned_list_of_addresses -> list of streets ('quartieri' dataset)
# list_of_long_strings -> titles + descriptions ('subito' and 'immobiliare' datasets)
# list_for_check -> agency addresses

def addressFinder2(raw_address_list, texts, agency_address):

  def standardize(text):
    # Makes everything lowercase and removes blanks
    text = text.lower().strip()
    # Removes punctuation
    text = re.sub(r"[^\w\s]", "", text)
    # Removes accents by converting letters with accent to their unaccented version
    text = unidecode(text)
    # Removes numbers
    text = re.sub(r"\d+", "", text)
    # fix whitespace issues
    text = text.replace(" ", " ")
    # Removes italian stopwords
    italian_stopwords = set(stopwords.words('italian'))
    tokens = word_tokenize(text)
    filtered_tokens = [word for word in tokens if word.casefold() not in italian_stopwords]
    text = ' '.join(filtered_tokens)

    return text
  
  # Return a dictionary with counted words
  def count_words(text, words_to_count):
    word_count_dict = defaultdict(int)
    words = text.split()
    for word in words:
      word_to_count_split = words_to_count.split()
      if word in word_to_count_split:
        word_count_dict[word] += 1
    return dict(word_count_dict)

  # Quality check of the dictionary got by count_words. It's good if a str in prefix is present and if it has more than one word
  def barrage(dictionary):
    prefix = ["corso", "largo", "ple", "piazza", "piazzale", "piazzetta", "strada", "vle", "viale", "via", "vicolo", 'foro']
    Q=False
    if len(dictionary) > 1:
      if set(dictionary.keys()) & set(prefix):
        for chiave in dictionary.keys():
          Q=True
    return Q

  # find if a prefix spawn in the text
  def find_word_position(text):
    prefix = ["corso", "largo", "ple", "piazza", "piazzale", "piazzetta", "strada", "vle", "viale", "via", "vicolo", 'foro']
    parole_trovate = []
    parole_testo = text.split()
    for indice, parola in enumerate(parole_testo):
      for prefisso in prefix:
        if parola.startswith(prefisso):
          tupla = (parola, indice)
          parole_trovate.append(tupla)
    return list(set(parole_trovate))

  # check the similarity between the streets from the dataset and from the text
  def check_streets(text, street):
    lista_tuple = []
    lista_indici = find_word_position(text)
    via_split = street[1].split()
    testo_split = text.split()
    for i in lista_indici:
      start = i[1]
      end = start + len(via_split)
      similarity = fuzz.token_sort_ratio(' '.join(testo_split[start:end]), street[1]) 
      lista_tuple.extend([(street, similarity)])
    return lista_tuple


  def best_match(lista, via_agenzia):
    lista = [[tupla for tupla in riga if via_agenzia not in tupla[0]] for riga in lista if any(via_agenzia not in tupla[0] for tupla in riga)]
    if any(any(sublist) for sublist in lista if sublist):
      
      def remove_piazza_duomo(strings):
        new_strings = []
        count = 0
        for sublist in strings:
          for tupla in sublist:
            if tupla[1] == 100 and tupla[0][1] != 'piazza duomo':
              count +=1
          new_sublist = [tupla for tupla in sublist if not ("piazza duomo" in tupla[0][1])]
          if new_sublist:
            new_strings.append(new_sublist)
        return new_strings if len(new_strings) > 1 and count != 0 else strings    
    
      lista = remove_piazza_duomo(lista)
      via_piu_alta = max((via for vie in lista for via in vie), key=lambda x: (x[1], len(x[0][1].split())), default=None)
      nome_via = via_piu_alta[0]
      return nome_via
    else:
      return 'Nessuna Via'


  def combine_dictionary(diz, streets):
    dizionario = {}
    for i in diz.keys():
      if diz[i] != 'Nessuna Via':
        dizionario[i] = streets[diz[i][0]]
      else:
        dizionario[i] = ''
    return dizionario
 
  #def combine_dictionary(diz, streets):
   # dizionario = {}
   # for record, valore in diz.items():
   #     found_match = False
    #    for via in streets:
     #       if fuzz.token_set_ratio(valore, via) >= 99.999:
      #          dizionario[record] = via
       #         found_match = True
        #        break
        #if not found_match:
         #   dizionario[record] = ''
   # return dizionario


################################################################################
  
  # standardize texts
  Testo_standardizzata = [standardize(descrizione) for descrizione in texts]

  # create the list of streets
  Vie = []
  for i in raw_address_list.keys():
    for j in range(len(raw_address_list[i])):
      Vie.append(raw_address_list[i][j])  
  # removes the streets with the "-"
  Vie2 = [via for via in Vie if "-" not in via]
  # removes ways with m1,m2... station
  metro = ['m1', 'm2', 'm3', 'm4', 'm5', 'stazione']
  Vie3 = [via_ for via_ in Vie2 if not any(parola in via_ for parola in metro)]
  # removes the ways that have only one word inside
  Vie4 = [via for via in Vie3 if len(via.split()) > 1]
  # removes "doubles" prefix
  prefix = ["corso", "largo", "ple", "piazza", "piazzale", "piazzetta", "strada", "vle", "viale", "via", "vicolo", 'foro']
  pattern = re.compile(r'\b(?:' + '|'.join(prefix) + r')\b.*\b(?:' + '|'.join(prefix) + r')\b')
  Vie5 = [via for via in Vie4 if not pattern.search(via)]
  Vie5_diz = {}
  Vie_standardizzate = {}
  # standardize streets
  for i in range(len(Vie5)):
    Vie5_diz[i] = Vie5[i]
    Vie_standardizzate[i] = standardize(Vie5[i]) 



  diz_associazioni={}
  for desch in range(len(Testo_standardizzata)):
    lista_via=[]
    for via in Vie_standardizzate.keys():
      qqq=count_words(Testo_standardizzata[desch], Vie_standardizzate[via])
      if barrage(qqq):
        lista_via.append([via, ' '.join(list(qqq.keys()))])
    diz_associazioni[desch] = lista_via

  diz = {}
  for indice_testo in range(len(Testo_standardizzata)):
    lista_tuple = [check_streets(Testo_standardizzata[indice_testo], via) for via in diz_associazioni[indice_testo]]
    diz[indice_testo] = best_match(lista_tuple, agency_address[indice_testo])


    
  return combine_dictionary(diz, Vie5_diz)

# It associates the street with the respective district. 
# It takes as argument the dataset and the dictionary ('quartieri') in which 
# we have the districts as keys and the lists of the respective streets as values.

def address_to_district(df, diz):
  chiave_trovata = []
  for i in df["Address"]:
    quartiere_trovato = None
    for chiave, valori in diz.items():
      if i in valori:
        quartiere_trovato = chiave
        break
    chiave_trovata.append(quartiere_trovato if quartiere_trovato else '')

  return chiave_trovata